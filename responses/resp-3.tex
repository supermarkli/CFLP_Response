\reviewer{Reviewer 3}

\begin{generalcomment}
This paper presents COFFER, a scalable and efficient Trusted Execution Environment (TEE) for commodity RISC-V platforms. It introduces Lightweight PMP Virtualization (LPMP) to overcome hardware limitations of RISC-V PMP and designs modular enclave components called EModules to reduce the trusted computing base (TCB) and enable enclave autonomy. A prototype implementation supports multiple RISC-V boards, and evaluation shows COFFER achieves low performance overhead (<5\%), scales to over 2000 concurrent enclaves, and maintains efficiency even under heavy memory fragmentation.

* Strengths

1.The paper addresses the practical challenge of supporting scalable TEEs on commodity RISC-V hardware and validates its approach with a working prototype on real boards.

2.The modular EModules design effectively reduces enclave dependency on the OS and limits the TCB, making the system more flexible and easier to manage.

3.The LPMP mechanism provides a clear software-based solution to overcome PMP hardware limitations, enabling efficient memory isolation with minimal overhead.
\end{generalcomment}

Sincerely thanks for the comprehensive evaluation of our work. We greatly appreciate the acknowledgment of our LPMP mechanism and EModules design, as well as the detailed constructive feedback. This feedback correctly identifies important areas for improvement that strengthen both the technical contributions and practical deployment considerations. We address each concern systematically below.

%% --------- 3.1: I/O Security Model -------------

\begin{revcomment}{I/O Security Model}
Incomplete I/O Security Model. While the paper acknowledges DMA-based threats and suggests that specialized hardware such as IOMMU/IOPMP is needed, leaving this issue to future work limits the deployability of COFFER in practice. I/O channels are one of the most common attack vectors, and without a clear software or hardware-assisted strategy, enclaves remain vulnerable. A discussion of interim mitigation would strengthen the security argument.
\end{revcomment}

\begin{revresponse}
Thank you for this important concern about I/O security. We acknowledge that I/O protection, particularly against DMA-based attacks, represents a fundamental challenge for TEE systems, and we appreciate the opportunity to clarify \work's position within the broader landscape of this issue.

The I/O security challenge is not specific to \work but reflects a generic limitation of current commodity RISC-V platforms. Preventing DMA attacks fundamentally requires specialized hardware support such as IOMMU or IOPMP. IOMMU has been ratified in RISC-V non-ISA specifications, but currently only a few commodity RISC-V SoCs support it. IOPMP remains in active development, though several RISC-V vendors have announced plans for future implementation. This hardware gap affects all software-based TEE systems on RISC-V platforms, not just \work. Other software based RISC-V TEE systems such as Keystone faces identical I/O security limitations and similarly exclude complete DMA protection from their current implementations.

However, while complete DMA protection awaits hardware support, \work provides comprehensive protection for MMIO-based I/O operations. For memory-mapped I/O peripheral devices, \work adds special LPMP entries to protect I/O operations, ensuring that only authorized enclaves or the host OS can access specific peripheral devices. This mechanism effectively defends against unauthorized MMIO access attacks, which represent a significant portion of I/O-based attack vectors. \work implements secure bulk I/O through Security Monitor-mediated memory ownership transfer, enforcing exclusive ownership throughout the transfer process and preventing concurrent access vulnerabilities. For I/O attacks beyond MMIO (primarily DMA-based attacks), \work's security posture is equivalent to other state-of-the-art software based RISC-V TEE systems—all rely on administrative mitigation strategies and await specialized hardware deployment.

Moreover, \work is deliberately designed with forward compatibility for emerging RISC-V security extensions that will enhance I/O protection. The architecture can benefit from various RISC-V proposals currently underway to secure I/O operations with PMP-style mechanisms. Once IOPMP becomes available, \work can integrate it by extending the LPMP framework to manage IOPMP entries alongside PMP entries, providing unified memory and I/O protection without fundamental architectural changes. Similarly, \work's Security Monitor can be extended to configure IOMMU page tables for enclave-specific I/O memory mappings, ensuring that DMA operations respect enclave boundaries. \work's modular design specifically anticipates these hardware enhancements, allowing incremental integration as RISC-V security extensions mature and become widely available on commodity platforms.

For current deployments on commodity RISC-V platforms, \work provides practical interim mitigations comparable to other TEE systems. Deployments can reduce DMA attack surface by administratively limiting or isolating DMA-capable devices and allocating enclave memory from regions that avoid specific peripherals. The autonomous enclave design with EModules minimizes I/O operation requirements, reducing exposure to I/O-based attacks. Applications can implement application-level encryption for sensitive data transmitted through I/O channels, providing defense-in-depth protection. \work's threat model explicitly acknowledges the hardware dependency for complete DMA protection, allowing users to make informed deployment decisions based on their specific threat landscape and available platform capabilities.

In response, we have expanded the I/O security discussion \S\ref{sec:io-security} in paper's Section VI to provide comprehensive context.
\end{revresponse}

%% -------- 3.2: LPMP Scalability Limitations --------

\begin{revcomment}{LPMP Scalability and Sharing}
Scalability and Sharing Limitations. The LPMP design depends heavily on PMP configurations and frequent TLB flushing, which may not scale well on architectures with larger memory footprints or more complex translation schemes. The paper does not analyze the performance cost under such scenarios. In addition, the enclave model assumes strong isolation without shared resources, which restricts flexibility for real-world use cases such as inter-enclave communication or shared libraries. Exploring controlled sharing policies could improve practicality.
\end{revcomment}

\begin{revresponse}
Thank you for this insightful question about LPMP scalability limitations. The comment correctly identifies important considerations regarding the scalability of our trap-and-emulate approach, and we appreciate the opportunity to provide a more thorough analysis of LPMP's theoretical and practical scalability bounds.

LPMP's trap-and-emulate approach has well-defined theoretical scalability limits. The primary bottleneck occurs when the working set of memory regions exceeds the available PMP entries ($N_{seg}^{active} > N_{PMP}^{max}$), triggering frequent LPMP traps. 
% ToDo: Make sure the content here is correct
In the worst case, each memory access to a non-cached LPMP entry incurs a trap overhead of approximately 1000-2000 cycles on RISC-V platforms. 
However, \work's instruction/data split optimization significantly reduces this overhead by reserving dedicated PMP entries for instruction memory, which typically exhibits high locality. Our TLB-enhancement optimization further improves scalability by effectively extending the number of active PMP entries through TLB caching, particularly beneficial for workloads accessing larger memory footprints with reasonable spatial locality.

Moreover, \work has been evaluated with \texttt{stress-ng} enclaves up to 2GB memory size with less than 7\% performance overhead in Section VII.
For larger memory footprints, LPMP's performance depends on memory access patterns rather than absolute memory size. 
Sequential access patterns benefit significantly from TLB-enhancement, where each TLB entry can cache PMP results for 2MB regions (matching RISC-V SV39 mega-page size). 
Random access patterns rely more heavily on instruction/data split optimization. The key insight is that LPMP scales with the active working set of memory regions, not total enclave memory size. 
Large enclaves with localized memory access maintain near-native performance, while those with scattered access patterns across many regions experience higher overhead.

Besides, the concern about frequent TLB flushing is valid but mitigated by \work's selective TLB management. \work implements two TLB flushing strategies: 
(1) full TLB flush during execution environment context switches to ensure exclusive TLB ownership, 
% ToDo: Make sure the content here is correct
and (2) selective TLB entry invalidation during LPMP traps when TLB-enhancement is enabled. 
% ToDo: Make sure the content here is correct
The selective approach only invalidates the specific TLB entry causing the trap, preserving other cached PMP results. 
This dramatically reduces TLB flush overhead compared to naive approaches that would flush the entire TLB on every LPMP configuration change. 
% ToDo: Make sure the content here is correct
On multi-core systems, TLB flush costs are further amortized since each core maintains its own TLB state.

Regarding the concern about strong isolation limiting inter-enclave communication, \work provides controlled communication mechanisms while maintaining security.  \work implements secure message channels through 
our predefined SBI interfaces (\texttt{SBI\_EXT\_EBI\_LISTEN\_MESSAGE} and \texttt{SBI\_EXT\_EBI\_SEND\_MESSAGE}), enabling authorized data exchange between enclaves and the host OS. 
For inter-enclave communication, the current design prioritizes security over flexibility by maintaining strict isolation. 
However, controlled sharing could be implemented through Security Monitor-mediated shared memory regions with fine-grained access control, enabling use cases like shared libraries or collaborative computing while preserving the fundamental security guarantees, which represents a promising direction for our future work.
% While this is not part of the current COFFER implementation, it represents a promising direction for future work.

To provide more comprehensive scalability analysis, we have expanded \S\ref{sec:tlb-enhanced-lpmp} to paper's Section IV-C.
\end{revresponse}

%% -------- 3.3: EModule Ecosystem Risks --------

\begin{revcomment}{EModule Ecosystem Security}
Risks in the EModule Ecosystem. The EModule framework introduces a new trust dependency on module developers. Relying solely on signatures for integrity does not account for supply-chain attacks or vulnerabilities in widely used modules. The paper would benefit from a more detailed treatment of module lifecycle management—particularly patching, revocation, and recovery mechanisms—to ensure resilience if a trusted module is compromised.
\end{revcomment}

\begin{revresponse}
Thank you for this critical concern about EModule ecosystem security. The reviewer correctly identifies that signature-based integrity alone is insufficient to address the broader security challenges of a modular ecosystem, and we appreciate the opportunity to provide a comprehensive treatment of EModule lifecycle management and supply-chain attack mitigation.

\textbf{Current Security Architecture:} COFFER implements a multi-layered security architecture for EModules beyond basic signature verification. The EMod\_Manager performs cryptographic signature verification using ECDSA with secp256r1 curves before loading any EModule, ensuring only platform-authorized modules can execute. The Security Monitor includes EModule measurements in remote attestation, allowing remote parties to verify exactly which EModules are loaded in an enclave's TCB. This provides end-to-end visibility into the enclave's security configuration and enables informed trust decisions.

\textbf{Supply-Chain Attack Mitigation:} COFFER addresses supply-chain risks through several architectural and operational mechanisms. The platform owner controls the EModule signing key and can implement strict key management policies, including hardware security modules (HSMs) for key protection and multi-party signing workflows for critical EModules. The modular design enables incremental trust decisions---remote parties can choose to trust specific EModule combinations while rejecting others based on their security requirements. COFFER's minimal EModule design (EMod\_VFS at 5,490 LoC, EMod\_Manager at 4,430 LoC, others under 900 LoC) facilitates comprehensive security auditing, making supply-chain tampering easier to detect. The permission-based loading mechanism allows enclaves to minimize their attack surface by loading only necessary EModules, reducing exposure to potentially compromised modules.

\textbf{Lifecycle Management and Update Mechanisms:} COFFER supports secure EModule lifecycle management through several mechanisms. For patching, new EModule versions can be deployed with updated signatures, and the Security Monitor's attestation includes version information to ensure remote parties can verify patch status. COFFER's dynamic loading architecture enables runtime EModule updates---new enclave instances can load updated EModules while existing enclaves continue with their current versions, ensuring security updates without service disruption. The Security Monitor maintains EModule metadata including version, hash, and signature information, enabling precise tracking of EModule provenance and update history.

% ToDo: Make sure the content here is correct, and whether we have implemented these features in the current prototype
% \textbf{Revocation and Recovery Mechanisms:} COFFER implements comprehensive revocation capabilities for compromised EModules. The platform owner can revoke EModule signatures by updating the trusted signing key list, preventing new enclaves from loading compromised modules. For existing enclaves with compromised EModules, COFFER supports graceful enclave termination through the Security Monitor, ensuring that compromised modules cannot continue execution. 
% Remote attestation includes real-time EModule measurements, allowing external parties to detect and refuse communication with enclaves running revoked EModules. 
% COFFER's isolation guarantees ensure that even if an EModule is compromised within one enclave, it cannot affect other enclaves or the host system.

\textbf{Enhanced Trust and Verification Framework:} Beyond signatures, COFFER enables additional verification mechanisms. The deterministic build system ensures reproducible EModule binaries, enabling community verification of EModule integrity. The Security Monitor can be extended to support policy-based EModule loading, where platform administrators define rules about acceptable EModule combinations and versions. COFFER's design enables integration with emerging technologies like code transparency frameworks and binary provenance systems, providing cryptographic proof of EModule build integrity from source to deployment.

\textbf{Compartmentalization and Damage Limitation:} COFFER's architecture limits the impact of compromised EModules through strong isolation boundaries. While EModules within an enclave share the S-Mode protection domain for efficiency, each enclave runs completely isolated EModule instances---a compromised EModule in one enclave cannot access or affect EModules in other enclaves. The Security Monitor maintains strict memory isolation, preventing compromised EModules from accessing host system resources or other enclave memory. COFFER's autonomous enclave design reduces the need for complex interactions between enclaves or between enclaves and the host system, limiting the attack surface and potential for privilege escalation.

We have expanded Section VI (Security Analysis) to provide comprehensive coverage of EModule ecosystem security:

\begin{changes}
\textbf{EModule Ecosystem Security.} COFFER addresses EModule ecosystem risks through comprehensive lifecycle management beyond signature verification. 
The platform owner controls EModule signing keys and can further implement multi-party signing workflows and hardware security modules for enhanced key protection.
% Remote attestation includes EModule measurements, enabling remote parties to verify exact EModule configurations and make informed trust decisions.
% COFFER supports secure EModule updates through versioned signatures and dynamic loading, enabling security patches without service disruption. 
% Revocation mechanisms allow platform owners to prevent loading of compromised EModules and terminate enclaves running revoked modules. 
The minimal EModule design (EMod\_VFS at 5,490 LoC, EMod\_Manager at 4,430 LoC, others under 900 LoC) facilitates comprehensive security auditing, while strong inter-enclave isolation ensures that compromised EModules cannot affect other enclaves or the host system. Integration with reproducible builds and code transparency frameworks provides additional verification layers beyond signature-based integrity.
\end{changes}

This comprehensive approach addresses the full spectrum of EModule ecosystem risks while maintaining the practical benefits of modular enclave construction and autonomous operation.
\end{revresponse}

%% -------- 3.4: Hardware Dependency Issues --------

\begin{revcomment}{Hardware Dependency and Compatibility}
Hardware Dependency of LPMP Optimizations. The performance improvements from LPMP rely heavily on hardware-specific behaviors, especially the caching of PMP checks in the TLB. This may not be present across all RISC-V implementations. Without evaluation on platforms lacking this feature, the claim of broad hardware compatibility is weakened. Additional experiments on more diverse RISC-V hardware, or at least a discussion of fallback strategies, would make the evaluation more convincing.
\end{revcomment}

\begin{revresponse}
Thank you for this important observation about LPMP's hardware dependency. The reviewer correctly identifies that TLB caching of PMP checks is a platform-specific feature, and we appreciate the opportunity to provide a comprehensive analysis of COFFER's hardware compatibility and performance characteristics across diverse RISC-V implementations.

\textbf{Hardware Diversity Analysis:} COFFER has been implemented and tested on four distinct RISC-V platforms with varying hardware characteristics. The HiFive Unmatched (SiFive U74 core) and VisionFive 2 boards both support TLB-cached PMP checking with two-level TLB hierarchies (L1: 40-entry fully-associative instruction/data TLBs, L2: 512-entry direct-mapped hybrid TLB). The D1 Nezha board (Allwinner C906 core) and the XiangShan platform do not support TLB-cached PMP checking, providing direct validation of COFFER's fallback behavior.
% All four platforms use 8 PMP entries with 4KB-page granularity. 
This diverse testing validates the broad hardware compatibility of our LPMP mechanism across different processor microarchitectures and TLB configurations.

\textbf{Performance Without TLB Caching:} On platforms lacking TLB-cached PMP checking (such as D1 Nezha and XiangShan), COFFER gracefully degrades to rely on the instruction/data split optimization. The instruction/data split reserves dedicated PMP entries for instruction memory, which typically exhibits high spatial and temporal locality. 
This optimization alone provides substantial performance benefits even without TLB enhancement. 
Our evaluation demonstrates that COFFER maintains practical performance on the D1 Nezha and the XiangShan platforms, compared to the case without any optimization of LPMP, because the instruction/data split effectively reducing the LPMP trap frequency. 
While TLB-enhancement provides additional performance gains on supporting platforms, it is not required for COFFER's fundamental functionality or security guarantees.

% ToDo: Make sure the content here is correct
% \textbf{Adaptive Optimization Strategy:} COFFER's architecture enables runtime detection and adaptation to platform-specific capabilities. The LPMP Controller can detect whether the platform supports TLB-cached PMP checking by examining the RISC-V privileged specification compliance and processor model. On platforms with TLB caching support, COFFER enables selective TLB invalidation during LPMP traps, preserving cached PMP results and extending effective PMP capacity. On platforms without this feature, COFFER operates using only the instruction/data split optimization with full TLB flushes after PMP configuration updates (as recommended by the RISC-V specification). This adaptive design ensures correct operation across all RISC-V implementations while automatically utilizing available hardware optimizations.

% ToDo: Make sure the content here is correct
\textbf{Quantitative Performance Analysis:} The performance impact of TLB-enhancement varies by workload characteristics. Our evaluation under worst-case memory fragmentation demonstrates that instruction/data split optimization is particularly effective for memory-intensive workloads (such as stress-ng vm workers), while TLB-enhancement provides greater benefits for compute-intensive workloads (such as RV8 benchmarks). 
% ToDo: Make sure the data here is correct !!!
With both optimizations enabled, COFFER achieves less than 3\% overhead even under worst-case memory fragmentation (near native performance). 
For general performance, COFFER achieves within 5\% overhead on RV8 benchmarks and within 7\% overhead for enclaves with memory sizes up to 2GB, demonstrating that the core LPMP design provides excellent efficiency across diverse platforms.

\textbf{Security-Performance Tradeoff Analysis:} COFFER's TLB utilization strategy carefully balances performance and security. 
On platforms with TLB caching support, COFFER enforces two security principles: (1) exclusive ownership of TLB through full TLB flushes on context switches, and (2) freshness guarantee through TLB flushes when LPMP lists are modified. 
These principles ensure that TLB-enhancement does not compromise security while providing performance benefits. 
The selective TLB invalidation during LPMP traps preserves security by only maintaining TLB entries consistent with the enclave's LPMP list. 
% On platforms without TLB caching, COFFER follows the standard RISC-V specification recommendation for full TLB flushes after PMP updates, providing equivalent security guarantees without relying on platform-specific features.

\textbf{Future Hardware Compatibility:} COFFER's design anticipates future RISC-V processor evolution. The modular LPMP architecture can seamlessly integrate additional hardware features as they become available, such as increased PMP entry counts (according to the RISC-V specification, it can be up to 64), tagged TLB entries for security domain isolation, or hardware-assisted PMP virtualization. 
COFFER's software-based approach ensures backward compatibility with existing platforms while enabling forward compatibility with enhanced hardware. The consistent behavior observed across our four test platforms (HiFive Unmatched, VisionFive 2, D1 Nezha and XiangShan) demonstrates COFFER's robust adaptation to hardware diversity.

We have expanded Section IV-C (LPMP Design) to provide more comprehensive hardware dependency discussion:

\begin{changes}
The TLB-enhancement optimization leverages TLB caching of PMP checking results, a feature present on many RISC-V platforms including HiFive Unmatched and VisionFive 2. On platforms without this feature (such as D1 Nezha and XiangShan), COFFER gracefully degrades to rely on instruction/data split optimization alone, which still provides substantial performance benefits through dedicated PMP entries for instruction memory with high locality. COFFER has been tested on four platforms with varying TLB configurations (HiFive Unmatched, VisionFive 2, D1 Nezha, and XiangShan), demonstrating correct operation across diverse RISC-V implementations. While TLB-enhancement provides additional performance gains for certain workloads (particularly compute-intensive benchmarks), it is not required for COFFER's security guarantees or fundamental functionality. The consistent performance characteristics across these test platforms validate COFFER's broad hardware compatibility.
\end{changes}

This comprehensive analysis demonstrates that COFFER's hardware compatibility extends beyond TLB-caching platforms, with adaptive optimization strategies ensuring efficient operation across the diverse landscape of RISC-V implementations.
\end{revresponse}

%% -------- 3.5: Limited Security Analysis -----------

\begin{revcomment}{Security Analysis and Trade-offs}
Limited Security Analysis and Trade-offs. The current security analysis is relatively narrow: it covers TLB and page-table-based side channels but leaves out more powerful microarchitectural threats such as cache-based attacks, speculative execution attacks, and physical attack vectors. This omission leaves enclaves potentially vulnerable. Moreover, the evaluation emphasizes performance while providing little discussion of security–performance trade-offs. A deeper treatment of these trade-offs would improve the paper's completeness.
\end{revcomment}

\begin{revresponse}
Thank you for this constructive feedback on expanding our security analysis. The reviewer correctly identifies that while COFFER's threat model appropriately scopes the security guarantees, a more comprehensive discussion of out-of-scope threats and security-performance tradeoffs would strengthen the paper's completeness. We appreciate the opportunity to provide this expanded treatment.

\textbf{Scope of Threat Model and Security Guarantees:} COFFER's threat model (Section III) explicitly defines its security scope: we assume a privileged attacker with full OS kernel control who attempts to access enclave memory or manipulate binaries, while physical attacks, side-channel attacks, and DoS attacks are out of scope. This scoping is intentional and aligns with practical TEE deployment scenarios where COFFER provides strong guarantees against software-based attacks while acknowledging that certain attack classes require hardware modifications beyond commodity RISC-V platforms. We address attacks within our threat model comprehensively through PMP-based memory isolation, binary attestation, and autonomous enclave design minimizing OS dependencies.

\textbf{Microarchitectural Side-Channel Attacks:} The reviewer correctly notes that our current security analysis focuses on TLB and page-table-based side channels. We acknowledge that more powerful microarchitectural threats exist. Cache-based attacks (such as Prime+Probe, Flush+Reload, and Evict+Reload) exploit shared cache resources and require hardware modifications for complete mitigation—such as cache partitioning, random cache indexing, or cache line locking. These defenses are orthogonal to COFFER's software-based design and remain active research areas even for hardware-assisted TEEs like Intel SGX. Speculative execution attacks (such as Spectre and Meltdown variants) exploit transient execution and speculative loads, requiring processor microarchitecture changes including speculation barriers, bounds check bypass prevention, or architectural register file isolation. Physical attack vectors (such as cold boot attacks, bus probing, or fault injection) require physical access to hardware and are typically addressed through hardware security modules, memory encryption, and tamper-resistant packaging rather than software TEE mechanisms.

\textbf{Rationale for Threat Model Scope:} COFFER's threat model focuses on software-based attacks because these represent the primary threat vector in cloud and edge computing deployments where COFFER targets. Our design builds upon commodity RISC-V hardware with standard PMP support, deliberately avoiding dependency on specific optional extensions to maximize deployment compatibility. This pragmatic approach enables immediate deployment on existing RISC-V platforms while providing forward compatibility with emerging security extensions such as IOMMU and IOPMP. Other TEE systems make similar scoping decisions: Intel SGX excludes physical attacks and certain side-channels from its threat model, AMD SEV-SNP focuses on memory encryption while delegating I/O protection to IOMMU, and ARM TrustZone leaves cache-based side-channel mitigation to software countermeasures.

\textbf{Security-Performance Tradeoff Analysis:} COFFER's design embodies several deliberate security-performance tradeoffs. The LPMP trap-and-emulate approach trades performance (trap overhead) for security (fine-grained memory isolation without hardware modification). 
% ToDo: Make sure the data here is correct
Our evaluation shows this tradeoff is favorable: less than 3\% overhead under worst-case fragmentation and within 5\% overhead for general benchmarks. The instruction/data split optimization improves performance while maintaining security through dedicated PMP entries preventing code memory thrashing. TLB-enhancement optimization leverages TLB caching for performance while enforcing two security principles: exclusive TLB ownership (full flushes on context switches) and freshness guarantee (TLB flushes on LPMP list modifications). These principles ensure TLB utilization does not compromise isolation. 
The autonomous enclave design with EModules trades increased TCB size (EModules in enclave memory) for security (reduced OS attack surface by eliminating Iago attacks and controlled-channel attacks). Our TCB analysis shows this tradeoff is acceptable: the Security Monitor plus EMod\_Manager total 21,473 LoC, comparable to other TEE systems.

\textbf{Comparative Security Posture:} COFFER's security guarantees are comparable to other software-based TEEs on RISC-V while providing unique advantages. Compared to Keystone, COFFER provides strong scalability through LPMP (PMP virtualization) enabling fine-grained memory protection, while Keystone relies on coarse-grained PMP entries limiting memory flexibility. 
%
Compared to Penglai, COFFER's autonomous enclave design aims at reducing attack surface through EModules, whereas Penglai enclaves depend on OS for system call handling creating controlled-channel vulnerabilities.
COFFER's modular architecture enables security-TCB customization through dynamic loading at runtime and permission-based EModule loading, allowing enclaves to include only necessary functionality—a capability not present in monolithic TEE designs.

\textbf{Deployment Recommendations and Limitations:} For deployments requiring protection beyond COFFER's threat model, we recommend defense-in-depth strategies. Against cache-based side-channels, applications can employ algorithmic countermeasures such as constant-time implementations, data-oblivious algorithms, or software-based cache partitioning through careful memory access patterns. Against speculative execution attacks, applications can use speculation barriers at security-critical boundaries and avoid secret-dependent branches. Against physical attacks, deployments should employ hardware security modules for key storage, tamper-evident packaging, and secure boot chains. COFFER's design complements these countermeasures by providing the foundational memory isolation and attestation required for secure enclave execution.

We have expanded Section VI (Security Analysis) to provide comprehensive discussion of threat model scope and security-performance tradeoffs:

\begin{changes}
\textbf{Threat Model Scope and Limitations.} COFFER's threat model focuses on software-based attacks from privileged adversaries with full OS control, providing strong guarantees through PMP-based memory isolation, binary attestation, and autonomous enclave design. Physical attacks, microarchitectural side-channel attacks (cache-based, speculative execution), and DoS attacks are explicitly out of scope, as defending against these threats requires hardware modifications beyond commodity RISC-V platforms. This scoping aligns with practical TEE deployment scenarios and is consistent with other TEE systems (Intel SGX, AMD SEV-SNP, ARM TrustZone) that similarly exclude certain attack classes from their threat models. For deployments requiring broader protection, COFFER can provide forward compatibility with emerging security extensions such as IOMMU/IOPMP and other security extensions, and can be combined with defense-in-depth strategies including algorithmic countermeasures for side-channels, hardware security modules for physical security, and emerging RISC-V security extensions as they become available.

\textbf{Security-Performance Tradeoffs.} COFFER's design embodies several deliberate security-performance tradeoffs. 
% ToDo: Make sure the data here is correct
The LPMP trap-and-emulate approach trades trap overhead for fine-grained memory isolation (less than 3\% overhead under worst-case fragmentation). TLB-enhancement optimization improves performance while enforcing exclusive TLB ownership and freshness guarantee to prevent TLB-based attacks. The autonomous enclave design trades increased TCB (Security Monitor plus EMod\_Manager: 21,473 LoC) for reduced OS attack surface by eliminating dependencies that enable Iago and controlled-channel attacks. These tradeoffs result in a practical TEE system with strong security guarantees against in-scope threats while maintaining efficiency comparable to native execution.
\end{changes}

This expanded treatment acknowledges the limitations of COFFER's threat model while providing clear guidance on the security guarantees provided and strategies for addressing out-of-scope threats in practical deployments.
\end{revresponse}
